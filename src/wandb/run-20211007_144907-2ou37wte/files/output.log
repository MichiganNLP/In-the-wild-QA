
Epoch 0:   0%|                                                                                                                                      | 0/3 [00:00<?, ?it/s]
  | Name  | Type                       | Params
-----------------------------------------------------
0 | model | T5ForConditionalGeneration | 222 M
-----------------------------------------------------
222 M     Trainable params
0         Non-trainable params
222 M     Total params
891.614   Total estimated model params size (MB)
Epoch 0:   0%|                                                                                                                                      | 0/3 [00:00<?, ?it/s]> /home/dnaihao/anaconda3/envs/442/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py(640)run_training_batch()
    639                     import ipdb;ipdb.set_trace()
--> 640                     if self.automatic_optimization:
    641

[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004l> /home/dnaihao/anaconda3/envs/442/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py(642)run_training_batch()
    641
--> 642                         def train_step_and_backward_closure():
    643                             result = self.training_step_and_backward(
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004l> /home/dnaihao/anaconda3/envs/442/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py(649)run_training_batch()
    648                         # optimizer step
--> 649                         self.optimizer_step(optimizer, opt_idx, batch_idx, train_step_and_backward_closure)
    650
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004l> /home/dnaihao/anaconda3/envs/442/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py(656)run_training_batch()
    655
--> 656                     if self._curr_step_result is None:
    657                         # user decided to skip optimization


[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7le[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?25l[?7lf[?7h[?12l[?25h[?25l[?7l.[?7h[?12l[?25h[?25l[?7l_[?7h[?12l[?25h[?25l[?7lc[?7h[?12l[?25h[?25l[?7lu[?7h[?12l[?25h[?25l[?7lr[?7h[?12l[?25h[?25l[?7lr[?7h[?12l[?25h[?25l[?7l_[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lt[?7h[?12l[?25h[?25l[?7le[?7h[?12l[?25h[?25l[?7lp[?7h[?12l[?25h[?25l[?7l_[?7h[?12l[?25h[?25l[?7lr[?7h[?12l[?25h[?25l[?7le[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lu[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?25lipdb> self._curr_step_result
[?7h[?12l[?25h[?2004l[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7le[?7h[?12l[?25h[?25l[?7lx[?7h[?12l[?25h[?25l[?7li[?7h[?12l[?25h[?25l[?7lt[?7h[?12l[?25ipdb> exit
Epoch 0:   0%|                                                                                                                                      | 0/3 [00:25<?, ?it/s]
Exiting Debugger.